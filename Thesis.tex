\documentclass[conference]{IEEEtran}

\usepackage{algorithmicx}
\usepackage[noend]{algpseudocode}
\usepackage[ruled,vlined]{algorithm2e}

\algblock{ParFor}{EndParFor}
% customising the new block
\algnewcommand\algorithmicparfor{\textbf{ParFor}}
\algnewcommand\algorithmicpardo{\textbf{do}}
\algnewcommand\algorithmicendparfor{\textbf{end\ ParFor}}
\algrenewtext{ParFor}[1]{\algorithmicparfor\ #1\ \algorithmicpardo}
\algrenewtext{EndParFor}{\algorithmicendparfor}

% for numbered citations
\usepackage{cite}
% for figures based on pdfs
\usepackage[pdftex]{graphicx}
 
 % Ben's packages
\usepackage{pgfplots}
\pgfplotsset{compat=1.13}
\usepackage{times}
\usepackage{listings}
\graphicspath{ {images/} }


\begin{document}

\title{Enabling Usage of Parallelism In Python}
\author{
\IEEEauthorblockA{Benjamin James Gaska}
\IEEEauthorblockA{Computer Science\\
University of Arizona\\
Tucson, Arizona\\
Email: bengaska@email.arizona.edu}}

\maketitle

\begin{abstract}

\end{abstract}

\section{Introduction}

%Paragraph 1, give problem. Scientific researchers like using high-level languages. We must work around their usage

The amount of data available to researchers has exploded in recent years, 
whole fields have arisen out of performing large dataset analysis.
Bioinformatics research involves searching through terrabytes of genetic data
to identify meaningful variations.\cite{bolstad2003comparison}
Social sciences are performing analysis of millions of tweets to detect political trends in lieu of traditional surveying methods. 
\cite{cody2016public}
Literary critics are building models of history of the novel through analysis of millions of books over hundreds of years.\cite{moretti2005graphs}
These users are searching for tools that enable them to quickly perform their 
with minimal effort.
The programming language chosen, and the libraries available in the language, 
has the most direct impact upon the user's work.

Several high-level programming languages have become very popular data analysis tasks, in particular SAS, R, and Python.\cite{kdnuggetSurvey}
Python in particular has quickly grown to be one of the most popular general purpose programming languages.
It is one of the most popular languages in use today for data 
analysis, both in raw number of users\cite{kdnuggetSurvey} and rate 
of growth of its user base.\cite{kdnuggetGrowthSurvey}
This popularity comes despite the fact that Python is quite slow.
Runtime comparisons of bioinformatic algorithms
show Python to be, on average, an order of magnitude slower than 
compiled languages such as C/C++ and Java.\cite{fourment2008comparison}
Long runtimes can lead to Python becoming infeasible
for computationally expensive analyses.


ParPython is a way to overcome the runtime bottleneck by enabling
easy usage of parallelism in the language. 
Inspired by OpenMP's pragma-based model\cite{dagum1998openmp}, 
ParPython allows users to specify which loops to parallelize. 
The specified loops are than
transformed to use the parallel tools available in Python. 
This is designed to minimally interfere with the underlying code logic.
Allowing users to place parallelism without having to significantly alter
the serial code.

This paper presents the following contributions: 
\begin{enumerate}
    \item ParPython a novel tool for transformation of serial Python code
    into parallel code,
    \item a survey of research scientist's programming habits, the
    bottlenecks they face and evidence that the ParPython model is 
    preferred over other parallelization options in Python,
    \item comparison of ParPython performance in a variety of 
    common Python benchmarks and libraries,
    \item a case study evaluating the usage of ParPython in
    a real-world planetary science code. 
\end{enumerate}

It is difficult to overcome the slowness of Python relative to
highly performant languages.
What is possible is making Python fast enough that it is not the 
bottleneck for the researcher's work.
This enables users to continue using Python, and the conveniences that 
brings, without being a impediment to the data pipelines that underpin 
modern scientific research.
In this way, we can enable researchers to perform their analysis
faster with less effort. This can free researcher's time to
do more.

\section{Motivation}

Scientific analysis is often limited by their data

\section{Implementation}

The ParPython toolset is implemented as a single new ParFor object. 
This object is placed by the user before a loop that they wish to have run in parallel. 
The user passes into the ParFor constructor the variables they wish to have returned from the loop body.
Then, before runtime the Abstract Syntax Tree is transformed by ParPython to produce code that uses the built-in Python parallel constructs.
Figure \ref{basicExample} shows a simple example of a singly-nested loop which build up two lists of values.
The only difference between the serial implementation and the ParPython implementation is the introduction of the ParFor object.

\begin{figure}[t]
\begin{lstlisting}[frame=single]
ParFor(output=(x,y))
for i in values:
    x.append(computeXValues(i))
    y.append(computeYValues(i))
\end{lstlisting}
\caption{Simple example of parallelizing a for loop using Parfor. The loop builds up lists x and y by performing some computation on each value in the given collection of values.}
\label{basicExample}
\end{figure}

\section{Results}

The ParPython implementation strives for simplicity, ease of use, and minimal difference between the serial and parallel code.
To this end, 40 benchmarks were chosen and an attempt was made to parallelize it using only the ParPython parallelism model.

The benchmarks were sampled from a larger set of benchmarks made up of the following:
\begin{itemize}
   \item Python Performance Suite\cite{pyPerformance}, a collection of benchmarks for comparison of Python implementations
   \item Numpy Benchmark Suite\cite{numpyPerformance}, the official test suite for Numpy 
   \item Scikit-Learn Benchmarks \cite{scikit-learn}, the official benchmarks for the popular Python machine learning library
   \item Natural Language Toolkit (NLTK) \cite{bird_2016}, an 
   open-source codebase for natural language processing in Python.
\end{itemize}
These were chosen because they represent a broad variety of code. 
This include implementation entirely in Python, and implementations 
that have a significant portion of its computation performed by calls to external C code.
CPython's native interfacing with C code makes the latter a particularly common usage case.
Further, Numpy, Scikit-Learn, and NLTK represent popular libraries for dataset analysis and scientific programming in Python.


ParPython was evaluated on the code in two ways. The first is how
easy it was to use ParPython with the pre-existing code, as well as 
determining in which use cases ParPython was able to 
parallelize the code at all.
The second takes the code the was able to be parallelized using our method and compares improvements in runtime of code.

\subsection{Ease of Implementation}

The core goal of the ParPython project is as simple an interface for specifying parallelism as possible. To this end, 
the benchmarks were classified into one of three possible categories:
\begin{enumerate}
   \item No modification required beyond inserting ParFor,
   \item some refactoring was required to implement using the ParFor,
   \item or code could not be parallelized using ParFor.
\end{enumerate}



%\begin{tikzpicture}
%\begin{axis}[
%	ylabel=\# of Benchmarks,
%	enlargelimits=0.05,
%	legend style={at={(0.5,-0.1)},
%	anchor=north,legend columns=-1},
%	ybar interval=0.7,
%]
%\addplot 
%	coordinates {(,388950) (2011,393007) 
%		(2010,398449) (2009,395972) (2008,398866)};
%\legend{}
%\end{axis}
%\end{tikzpicture}

\subsection{Performance}






%\section{Related Work}

%Beazley \cite{beazley2010understanding} provides an excellent overview to the problems Python's GIL causes for multithreading.

%PyMP\cite{pymp} is an library for Python that allows parallel iterators 
%Unix environments. It relies on making direct calls to the fork() system 
%call, and is not compatible with non-Unix environments. Further, it does
%not support reductions and requires rewriting the serial code to fit with
%the model.

\section{Conclusions}


\bibliographystyle{IEEEtran}
\bibliography{Thesis}
\end{document}
